Batch size:		64
Total epochs:		20
Operation:		deconvolution
k-sample:		0

Learning rate:		0.0001

Model capacity:		57648587

Finished loading data...
|	Saving ./result/imgs/deconvolution_epoch_0_train.png...
|	Saving ./result/imgs/deconvolution_epoch_0_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_0_test.png...
|	Saving ./result/imgs/deconvolution_epoch_0_test_org.png...
|	Epoch 1:
|		Train:
|		batch #:100	loss=7390.07	kl=132.17	reconst_loss=7257.91	use 26.53 sec
|		batch #:200	loss=6818.51	kl=128.68	reconst_loss=6689.83	use 27.38 sec
|		batch #:300	loss=6687.22	kl=128.22	reconst_loss=6559.00	use 28.31 sec
|		batch #:400	loss=6630.24	kl=128.15	reconst_loss=6502.08	use 28.32 sec
|		batch #:500	loss=6589.45	kl=128.99	reconst_loss=6460.46	use 28.29 sec
|		batch #:600	loss=6538.68	kl=129.25	reconst_loss=6409.43	use 28.30 sec
|		batch #:700	loss=6508.92	kl=128.62	reconst_loss=6380.30	use 28.31 sec
|		batch #:800	loss=6522.98	kl=130.13	reconst_loss=6392.85	use 28.31 sec
|		batch #:900	loss=6485.34	kl=129.10	reconst_loss=6356.24	use 28.31 sec
|		batch #:1000	loss=6485.50	kl=129.98	reconst_loss=6355.52	use 28.32 sec
|		batch #:1100	loss=6473.02	kl=130.44	reconst_loss=6342.58	use 28.28 sec
|		batch #:1200	loss=6456.92	kl=130.38	reconst_loss=6326.53	use 28.27 sec
|		batch #:1300	loss=6430.31	kl=130.23	reconst_loss=6300.07	use 28.29 sec
|		batch #:1400	loss=6448.89	kl=131.21	reconst_loss=6317.68	use 28.33 sec
|		batch #:1500	loss=6435.25	kl=131.28	reconst_loss=6303.97	use 28.34 sec
|		batch #:1600	loss=6400.47	kl=131.19	reconst_loss=6269.29	use 28.31 sec
|		batch #:1700	loss=6406.49	kl=131.67	reconst_loss=6274.82	use 28.29 sec
|		batch #:1800	loss=6394.09	kl=132.11	reconst_loss=6261.98	use 28.30 sec
|		batch #:1900	loss=6393.24	kl=131.09	reconst_loss=6262.15	use 28.31 sec
|		batch #:2000	loss=6383.56	kl=131.36	reconst_loss=6252.20	use 28.31 sec
|		batch #:2100	loss=6400.07	kl=131.63	reconst_loss=6268.43	use 28.30 sec
|		batch #:2200	loss=6395.94	kl=131.91	reconst_loss=6264.03	use 28.27 sec
|		batch #:2300	loss=6376.60	kl=131.32	reconst_loss=6245.28	use 28.27 sec
|		batch #:2400	loss=6376.20	kl=131.56	reconst_loss=6244.65	use 28.31 sec
|		batch #:2500	loss=6380.39	kl=131.57	reconst_loss=6248.82	use 28.31 sec
|		batch #:2600	loss=6373.25	kl=132.11	reconst_loss=6241.14	use 28.34 sec
|		batch #:2700	loss=6377.55	kl=131.34	reconst_loss=6246.21	use 28.34 sec
|		batch #:2800	loss=6367.88	kl=131.40	reconst_loss=6236.49	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_1_train.png...
|	Saving ./result/imgs/deconvolution_epoch_1_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_1_test.png...
|	Saving ./result/imgs/deconvolution_epoch_1_test_org.png...
|	Train loss=6494.984298732834

|		Eval test:
|		batch #:100	loss=6361.44	kl=130.53	reconst_loss=6230.90	use 10.80 sec
|		batch #:200	loss=6353.62	kl=130.98	reconst_loss=6222.64	use 10.54 sec
|		batch #:300	loss=6370.02	kl=130.53	reconst_loss=6239.49	use 10.54 sec
|	Test loss=6357.480804057061

Finished saving model: ./result/model/deconvolution1.pt
|	Epoch 2:
|		Train:
|		batch #:100	loss=6346.76	kl=131.49	reconst_loss=6215.27	use 28.09 sec
|		batch #:200	loss=6357.39	kl=131.26	reconst_loss=6226.13	use 28.28 sec
|		batch #:300	loss=6330.85	kl=130.54	reconst_loss=6200.30	use 28.33 sec
|		batch #:400	loss=6349.37	kl=130.47	reconst_loss=6218.90	use 28.32 sec
|		batch #:500	loss=6372.02	kl=130.84	reconst_loss=6241.18	use 28.32 sec
|		batch #:600	loss=6327.19	kl=130.04	reconst_loss=6197.15	use 28.33 sec
|		batch #:700	loss=6360.10	kl=130.00	reconst_loss=6230.10	use 28.34 sec
|		batch #:800	loss=6352.90	kl=129.71	reconst_loss=6223.19	use 28.32 sec
|		batch #:900	loss=6325.82	kl=130.36	reconst_loss=6195.46	use 28.33 sec
|		batch #:1000	loss=6348.00	kl=129.45	reconst_loss=6218.55	use 28.29 sec
|		batch #:1100	loss=6334.57	kl=129.35	reconst_loss=6205.23	use 28.28 sec
|		batch #:1200	loss=6320.33	kl=129.42	reconst_loss=6190.91	use 28.31 sec
|		batch #:1300	loss=6352.28	kl=129.59	reconst_loss=6222.69	use 28.32 sec
|		batch #:1400	loss=6353.54	kl=128.99	reconst_loss=6224.55	use 28.32 sec
|		batch #:1500	loss=6334.06	kl=128.61	reconst_loss=6205.45	use 28.34 sec
|		batch #:1600	loss=6345.87	kl=128.52	reconst_loss=6217.35	use 28.34 sec
|		batch #:1700	loss=6338.86	kl=128.55	reconst_loss=6210.31	use 28.31 sec
|		batch #:1800	loss=6341.04	kl=127.85	reconst_loss=6213.18	use 28.34 sec
|		batch #:1900	loss=6326.03	kl=127.70	reconst_loss=6198.33	use 28.31 sec
|		batch #:2000	loss=6356.76	kl=127.53	reconst_loss=6229.23	use 28.28 sec
|		batch #:2100	loss=6359.37	kl=127.10	reconst_loss=6232.27	use 28.29 sec
|		batch #:2200	loss=6318.43	kl=127.22	reconst_loss=6191.21	use 28.31 sec
|		batch #:2300	loss=6316.72	kl=126.95	reconst_loss=6189.77	use 28.31 sec
|		batch #:2400	loss=6342.13	kl=126.52	reconst_loss=6215.62	use 28.35 sec
|		batch #:2500	loss=6307.91	kl=126.51	reconst_loss=6181.39	use 28.35 sec
|		batch #:2600	loss=6331.09	kl=126.51	reconst_loss=6204.58	use 28.35 sec
|		batch #:2700	loss=6303.72	kl=125.85	reconst_loss=6177.87	use 28.29 sec
|		batch #:2800	loss=6324.13	kl=126.15	reconst_loss=6197.98	use 28.28 sec
|	Saving ./result/imgs/deconvolution_epoch_2_train.png...
|	Saving ./result/imgs/deconvolution_epoch_2_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_2_test.png...
|	Saving ./result/imgs/deconvolution_epoch_2_test_org.png...
|	Train loss=6337.791240655987

|		Eval test:
|		batch #:100	loss=6315.30	kl=128.64	reconst_loss=6186.66	use 10.96 sec
|		batch #:200	loss=6307.90	kl=129.16	reconst_loss=6178.74	use 10.58 sec
|		batch #:300	loss=6324.03	kl=128.61	reconst_loss=6195.42	use 10.59 sec
|	Test loss=6311.498034513449

Finished saving model: ./result/model/deconvolution2.pt
|	Epoch 3:
|		Train:
|		batch #:100	loss=6318.24	kl=125.32	reconst_loss=6192.92	use 28.13 sec
|		batch #:200	loss=6314.92	kl=125.49	reconst_loss=6189.43	use 28.28 sec
|		batch #:300	loss=6304.22	kl=125.31	reconst_loss=6178.91	use 28.28 sec
|		batch #:400	loss=6318.21	kl=125.25	reconst_loss=6192.97	use 28.26 sec
|		batch #:500	loss=6331.39	kl=124.64	reconst_loss=6206.75	use 28.28 sec
|		batch #:600	loss=6326.48	kl=124.24	reconst_loss=6202.25	use 28.32 sec
|		batch #:700	loss=6301.27	kl=125.04	reconst_loss=6176.24	use 28.30 sec
|		batch #:800	loss=6305.23	kl=124.70	reconst_loss=6180.53	use 28.31 sec
|		batch #:900	loss=6311.14	kl=124.40	reconst_loss=6186.74	use 28.32 sec
|		batch #:1000	loss=6344.66	kl=124.04	reconst_loss=6220.63	use 28.29 sec
|		batch #:1100	loss=6317.61	kl=124.27	reconst_loss=6193.35	use 28.30 sec
|		batch #:1200	loss=6281.64	kl=123.95	reconst_loss=6157.70	use 28.33 sec
|		batch #:1300	loss=6310.65	kl=123.92	reconst_loss=6186.73	use 28.34 sec
|		batch #:1400	loss=6300.08	kl=123.45	reconst_loss=6176.62	use 28.36 sec
|		batch #:1500	loss=6323.05	kl=122.71	reconst_loss=6200.34	use 28.34 sec
|		batch #:1600	loss=6314.12	kl=123.07	reconst_loss=6191.05	use 28.31 sec
|		batch #:1700	loss=6308.65	kl=123.49	reconst_loss=6185.16	use 28.30 sec
|		batch #:1800	loss=6304.71	kl=122.74	reconst_loss=6181.96	use 28.31 sec
|		batch #:1900	loss=6298.13	kl=123.17	reconst_loss=6174.96	use 28.36 sec
|		batch #:2000	loss=6302.98	kl=122.85	reconst_loss=6180.12	use 28.37 sec
|		batch #:2100	loss=6304.02	kl=123.20	reconst_loss=6180.83	use 28.33 sec
|		batch #:2200	loss=6297.02	kl=122.60	reconst_loss=6174.43	use 28.29 sec
|		batch #:2300	loss=6273.15	kl=122.75	reconst_loss=6150.41	use 28.31 sec
|		batch #:2400	loss=6295.18	kl=122.50	reconst_loss=6172.68	use 28.30 sec
|		batch #:2500	loss=6285.00	kl=122.60	reconst_loss=6162.40	use 28.32 sec
|		batch #:2600	loss=6284.70	kl=122.53	reconst_loss=6162.16	use 28.32 sec
|		batch #:2700	loss=6303.69	kl=122.00	reconst_loss=6181.69	use 28.29 sec
|		batch #:2800	loss=6280.11	kl=122.64	reconst_loss=6157.47	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_3_train.png...
|	Saving ./result/imgs/deconvolution_epoch_3_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_3_test.png...
|	Saving ./result/imgs/deconvolution_epoch_3_test_org.png...
|	Train loss=6305.390779248201

|		Eval test:
|		batch #:100	loss=6287.47	kl=120.03	reconst_loss=6167.44	use 10.84 sec
|		batch #:200	loss=6280.88	kl=120.47	reconst_loss=6160.41	use 10.56 sec
|		batch #:300	loss=6296.83	kl=119.97	reconst_loss=6176.86	use 10.56 sec
|	Test loss=6284.091339497627

Finished saving model: ./result/model/deconvolution3.pt
|	Epoch 4:
|		Train:
|		batch #:100	loss=6279.33	kl=122.48	reconst_loss=6156.85	use 28.02 sec
|		batch #:200	loss=6308.08	kl=122.37	reconst_loss=6185.71	use 28.33 sec
|		batch #:300	loss=6287.70	kl=121.84	reconst_loss=6165.86	use 28.32 sec
|		batch #:400	loss=6290.79	kl=121.95	reconst_loss=6168.84	use 28.28 sec
|		batch #:500	loss=6279.71	kl=121.88	reconst_loss=6157.84	use 28.30 sec
|		batch #:600	loss=6283.44	kl=121.67	reconst_loss=6161.77	use 28.30 sec
|		batch #:700	loss=6266.16	kl=122.07	reconst_loss=6144.09	use 28.28 sec
|		batch #:800	loss=6270.78	kl=121.83	reconst_loss=6148.95	use 28.33 sec
|		batch #:900	loss=6289.14	kl=121.88	reconst_loss=6167.26	use 28.33 sec
|		batch #:1000	loss=6303.65	kl=121.46	reconst_loss=6182.19	use 28.30 sec
|		batch #:1100	loss=6289.64	kl=121.53	reconst_loss=6168.12	use 28.35 sec
|		batch #:1200	loss=6308.38	kl=121.30	reconst_loss=6187.08	use 28.34 sec
|		batch #:1300	loss=6302.69	kl=121.80	reconst_loss=6180.89	use 28.32 sec
|		batch #:1400	loss=6274.68	kl=121.68	reconst_loss=6153.01	use 28.33 sec
|		batch #:1500	loss=6275.04	kl=121.68	reconst_loss=6153.36	use 28.31 sec
|		batch #:1600	loss=6270.16	kl=121.51	reconst_loss=6148.66	use 28.28 sec
|		batch #:1700	loss=6291.88	kl=121.39	reconst_loss=6170.49	use 28.32 sec
|		batch #:1800	loss=6272.67	kl=121.35	reconst_loss=6151.31	use 28.34 sec
|		batch #:1900	loss=6281.56	kl=121.24	reconst_loss=6160.32	use 28.36 sec
|		batch #:2000	loss=6277.57	kl=121.21	reconst_loss=6156.36	use 28.40 sec
|		batch #:2100	loss=6261.83	kl=121.36	reconst_loss=6140.47	use 28.38 sec
|		batch #:2200	loss=6276.54	kl=121.22	reconst_loss=6155.32	use 28.35 sec
|		batch #:2300	loss=6270.18	kl=121.23	reconst_loss=6148.94	use 28.37 sec
|		batch #:2400	loss=6286.11	kl=121.40	reconst_loss=6164.71	use 28.35 sec
|		batch #:2500	loss=6283.52	kl=121.14	reconst_loss=6162.37	use 28.35 sec
|		batch #:2600	loss=6313.58	kl=120.97	reconst_loss=6192.61	use 28.34 sec
|		batch #:2700	loss=6296.99	kl=120.35	reconst_loss=6176.64	use 28.34 sec
|		batch #:2800	loss=6290.74	kl=121.12	reconst_loss=6169.62	use 28.37 sec
|	Saving ./result/imgs/deconvolution_epoch_4_train.png...
|	Saving ./result/imgs/deconvolution_epoch_4_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_4_test.png...
|	Saving ./result/imgs/deconvolution_epoch_4_test_org.png...
|	Train loss=6285.2613415274545

|		Eval test:
|		batch #:100	loss=6283.01	kl=120.34	reconst_loss=6162.67	use 11.08 sec
|		batch #:200	loss=6276.74	kl=120.71	reconst_loss=6156.04	use 10.59 sec
|		batch #:300	loss=6291.69	kl=120.27	reconst_loss=6171.41	use 10.60 sec
|	Test loss=6279.513552895075

Finished saving model: ./result/model/deconvolution4.pt
|	Epoch 5:
|		Train:
|		batch #:100	loss=6273.15	kl=120.85	reconst_loss=6152.29	use 28.10 sec
|		batch #:200	loss=6285.54	kl=120.58	reconst_loss=6164.96	use 28.32 sec
|		batch #:300	loss=6279.27	kl=120.88	reconst_loss=6158.39	use 28.33 sec
|		batch #:400	loss=6262.26	kl=121.24	reconst_loss=6141.02	use 28.33 sec
|		batch #:500	loss=6270.02	kl=120.78	reconst_loss=6149.24	use 28.33 sec
|		batch #:600	loss=6291.09	kl=120.73	reconst_loss=6170.36	use 28.31 sec
|		batch #:700	loss=6301.40	kl=120.43	reconst_loss=6180.98	use 28.29 sec
|		batch #:800	loss=6291.47	kl=121.12	reconst_loss=6170.35	use 28.28 sec
|		batch #:900	loss=6281.29	kl=120.06	reconst_loss=6161.23	use 28.29 sec
|		batch #:1000	loss=6287.12	kl=120.65	reconst_loss=6166.47	use 28.29 sec
|		batch #:1100	loss=6279.79	kl=120.60	reconst_loss=6159.19	use 28.35 sec
|		batch #:1200	loss=6277.20	kl=120.59	reconst_loss=6156.61	use 28.36 sec
|		batch #:1300	loss=6255.01	kl=120.61	reconst_loss=6134.40	use 28.36 sec
|		batch #:1400	loss=6261.19	kl=120.14	reconst_loss=6141.05	use 28.32 sec
|		batch #:1500	loss=6270.56	kl=120.44	reconst_loss=6150.12	use 28.31 sec
|		batch #:1600	loss=6296.19	kl=120.35	reconst_loss=6175.84	use 28.34 sec
|		batch #:1700	loss=6258.50	kl=120.27	reconst_loss=6138.22	use 28.36 sec
|		batch #:1800	loss=6286.36	kl=121.04	reconst_loss=6165.32	use 28.35 sec
|		batch #:1900	loss=6266.37	kl=120.20	reconst_loss=6146.17	use 28.34 sec
|		batch #:2000	loss=6263.90	kl=120.43	reconst_loss=6143.47	use 28.28 sec
|		batch #:2100	loss=6265.40	kl=119.89	reconst_loss=6145.50	use 28.30 sec
|		batch #:2200	loss=6266.05	kl=120.57	reconst_loss=6145.49	use 28.34 sec
|		batch #:2300	loss=6289.42	kl=120.79	reconst_loss=6168.63	use 28.35 sec
|		batch #:2400	loss=6279.03	kl=119.89	reconst_loss=6159.14	use 28.36 sec
|		batch #:2500	loss=6264.44	kl=119.90	reconst_loss=6144.54	use 28.33 sec
|		batch #:2600	loss=6246.45	kl=120.53	reconst_loss=6125.93	use 28.29 sec
|		batch #:2700	loss=6264.71	kl=119.82	reconst_loss=6144.88	use 28.28 sec
|		batch #:2800	loss=6278.86	kl=119.88	reconst_loss=6158.98	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_5_train.png...
|	Saving ./result/imgs/deconvolution_epoch_5_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_5_test.png...
|	Saving ./result/imgs/deconvolution_epoch_5_test_org.png...
|	Train loss=6274.181972772793

|		Eval test:
|		batch #:100	loss=6275.58	kl=116.15	reconst_loss=6159.43	use 10.99 sec
|		batch #:200	loss=6268.91	kl=116.52	reconst_loss=6152.39	use 10.56 sec
|		batch #:300	loss=6284.48	kl=116.16	reconst_loss=6168.32	use 10.56 sec
|	Test loss=6271.999618337124

Finished saving model: ./result/model/deconvolution5.pt
|	Epoch 6:
|		Train:
|		batch #:100	loss=6266.02	kl=120.39	reconst_loss=6145.63	use 28.09 sec
|		batch #:200	loss=6267.72	kl=119.78	reconst_loss=6147.94	use 28.31 sec
|		batch #:300	loss=6278.70	kl=120.18	reconst_loss=6158.52	use 28.30 sec
|		batch #:400	loss=6265.22	kl=119.58	reconst_loss=6145.64	use 28.29 sec
|		batch #:500	loss=6272.74	kl=120.73	reconst_loss=6152.01	use 28.30 sec
|		batch #:600	loss=6298.20	kl=120.39	reconst_loss=6177.81	use 28.31 sec
|		batch #:700	loss=6279.06	kl=119.71	reconst_loss=6159.35	use 28.31 sec
|		batch #:800	loss=6263.55	kl=119.94	reconst_loss=6143.61	use 28.28 sec
|		batch #:900	loss=6255.51	kl=119.98	reconst_loss=6135.53	use 28.28 sec
|		batch #:1000	loss=6259.54	kl=119.82	reconst_loss=6139.72	use 28.30 sec
|		batch #:1100	loss=6270.42	kl=120.04	reconst_loss=6150.37	use 28.30 sec
|		batch #:1200	loss=6251.54	kl=119.83	reconst_loss=6131.71	use 28.30 sec
|		batch #:1300	loss=6254.92	kl=120.23	reconst_loss=6134.69	use 28.30 sec
|		batch #:1400	loss=6275.27	kl=119.47	reconst_loss=6155.80	use 28.30 sec
|		batch #:1500	loss=6268.20	kl=120.27	reconst_loss=6147.94	use 28.32 sec
|		batch #:1600	loss=6249.93	kl=119.25	reconst_loss=6130.69	use 28.32 sec
|		batch #:1700	loss=6280.82	kl=119.47	reconst_loss=6161.35	use 28.32 sec
|		batch #:1800	loss=6253.14	kl=119.92	reconst_loss=6133.22	use 28.32 sec
|		batch #:1900	loss=6255.31	kl=119.42	reconst_loss=6135.89	use 28.30 sec
|		batch #:2000	loss=6277.60	kl=119.51	reconst_loss=6158.09	use 28.31 sec
|		batch #:2100	loss=6253.48	kl=119.20	reconst_loss=6134.28	use 28.30 sec
|		batch #:2200	loss=6268.85	kl=119.63	reconst_loss=6149.22	use 28.28 sec
|		batch #:2300	loss=6257.31	kl=119.72	reconst_loss=6137.60	use 28.29 sec
|		batch #:2400	loss=6267.81	kl=119.48	reconst_loss=6148.33	use 28.31 sec
|		batch #:2500	loss=6264.80	kl=119.21	reconst_loss=6145.59	use 28.31 sec
|		batch #:2600	loss=6259.19	kl=119.63	reconst_loss=6139.56	use 28.32 sec
|		batch #:2700	loss=6285.19	kl=119.05	reconst_loss=6166.14	use 28.33 sec
|		batch #:2800	loss=6269.57	kl=119.04	reconst_loss=6150.53	use 28.32 sec
|	Saving ./result/imgs/deconvolution_epoch_6_train.png...
|	Saving ./result/imgs/deconvolution_epoch_6_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_6_test.png...
|	Saving ./result/imgs/deconvolution_epoch_6_test_org.png...
|	Train loss=6266.734925666078

|		Eval test:
|		batch #:100	loss=6264.38	kl=120.24	reconst_loss=6144.14	use 10.85 sec
|		batch #:200	loss=6258.18	kl=120.63	reconst_loss=6137.55	use 10.55 sec
|		batch #:300	loss=6273.86	kl=120.15	reconst_loss=6153.71	use 10.53 sec
|	Test loss=6261.165168858782

Finished saving model: ./result/model/deconvolution6.pt
|	Epoch 7:
|		Train:
|		batch #:100	loss=6248.94	kl=119.44	reconst_loss=6129.50	use 28.07 sec
|		batch #:200	loss=6241.30	kl=119.86	reconst_loss=6121.44	use 28.30 sec
|		batch #:300	loss=6265.73	kl=119.62	reconst_loss=6146.11	use 28.31 sec
|		batch #:400	loss=6276.73	kl=119.28	reconst_loss=6157.45	use 28.33 sec
|		batch #:500	loss=6252.33	kl=119.33	reconst_loss=6133.01	use 28.34 sec
|		batch #:600	loss=6255.85	kl=119.29	reconst_loss=6136.57	use 28.35 sec
|		batch #:700	loss=6270.21	kl=119.25	reconst_loss=6150.96	use 28.32 sec
|		batch #:800	loss=6268.73	kl=119.30	reconst_loss=6149.43	use 28.31 sec
|		batch #:900	loss=6250.90	kl=119.68	reconst_loss=6131.22	use 28.34 sec
|		batch #:1000	loss=6261.00	kl=119.36	reconst_loss=6141.63	use 28.35 sec
|		batch #:1100	loss=6248.88	kl=119.63	reconst_loss=6129.25	use 28.35 sec
|		batch #:1200	loss=6261.97	kl=119.59	reconst_loss=6142.39	use 28.31 sec
|		batch #:1300	loss=6259.58	kl=119.29	reconst_loss=6140.29	use 28.29 sec
|		batch #:1400	loss=6240.00	kl=118.95	reconst_loss=6121.05	use 28.29 sec
|		batch #:1500	loss=6281.93	kl=119.70	reconst_loss=6162.22	use 28.33 sec
|		batch #:1600	loss=6261.27	kl=119.28	reconst_loss=6141.99	use 28.38 sec
|		batch #:1700	loss=6281.64	kl=118.65	reconst_loss=6162.99	use 28.40 sec
|		batch #:1800	loss=6273.60	kl=119.09	reconst_loss=6154.51	use 28.36 sec
|		batch #:1900	loss=6254.34	kl=118.67	reconst_loss=6135.67	use 28.35 sec
|		batch #:2000	loss=6258.37	kl=119.05	reconst_loss=6139.32	use 28.35 sec
|		batch #:2100	loss=6261.12	kl=118.74	reconst_loss=6142.38	use 28.33 sec
|		batch #:2200	loss=6241.32	kl=119.14	reconst_loss=6122.19	use 28.35 sec
|		batch #:2300	loss=6257.92	kl=119.38	reconst_loss=6138.53	use 28.34 sec
|		batch #:2400	loss=6260.04	kl=119.01	reconst_loss=6141.03	use 28.31 sec
|		batch #:2500	loss=6259.73	kl=119.23	reconst_loss=6140.50	use 28.31 sec
|		batch #:2600	loss=6285.19	kl=119.29	reconst_loss=6165.90	use 28.35 sec
|		batch #:2700	loss=6259.69	kl=119.36	reconst_loss=6140.33	use 28.37 sec
|		batch #:2800	loss=6260.83	kl=119.21	reconst_loss=6141.62	use 28.35 sec
|	Saving ./result/imgs/deconvolution_epoch_7_train.png...
|	Saving ./result/imgs/deconvolution_epoch_7_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_7_test.png...
|	Saving ./result/imgs/deconvolution_epoch_7_test_org.png...
|	Train loss=6261.1236304473605

|		Eval test:
|		batch #:100	loss=6256.70	kl=119.87	reconst_loss=6136.83	use 10.89 sec
|		batch #:200	loss=6250.53	kl=120.24	reconst_loss=6130.29	use 10.57 sec
|		batch #:300	loss=6266.53	kl=119.80	reconst_loss=6146.73	use 10.58 sec
|	Test loss=6253.603341018097

Finished saving model: ./result/model/deconvolution7.pt
|	Epoch 8:
|		Train:
|		batch #:100	loss=6258.40	kl=119.27	reconst_loss=6139.13	use 28.27 sec
|		batch #:200	loss=6252.56	kl=119.25	reconst_loss=6133.31	use 28.32 sec
|		batch #:300	loss=6240.92	kl=119.73	reconst_loss=6121.19	use 28.35 sec
|		batch #:400	loss=6256.48	kl=119.09	reconst_loss=6137.39	use 28.37 sec
|		batch #:500	loss=6247.03	kl=119.58	reconst_loss=6127.46	use 28.35 sec
|		batch #:600	loss=6276.26	kl=118.96	reconst_loss=6157.31	use 28.33 sec
|		batch #:700	loss=6268.15	kl=118.78	reconst_loss=6149.37	use 28.30 sec
|		batch #:800	loss=6245.73	kl=118.47	reconst_loss=6127.25	use 28.31 sec
|		batch #:900	loss=6268.62	kl=119.37	reconst_loss=6149.26	use 28.34 sec
|		batch #:1000	loss=6270.41	kl=118.67	reconst_loss=6151.74	use 28.34 sec
|		batch #:1100	loss=6260.65	kl=118.91	reconst_loss=6141.73	use 28.33 sec
|		batch #:1200	loss=6260.90	kl=119.31	reconst_loss=6141.59	use 28.30 sec
|		batch #:1300	loss=6261.26	kl=118.92	reconst_loss=6142.33	use 28.32 sec
|		batch #:1400	loss=6271.42	kl=118.72	reconst_loss=6152.70	use 28.35 sec
|		batch #:1500	loss=6256.94	kl=119.20	reconst_loss=6137.74	use 28.38 sec
|		batch #:1600	loss=6258.74	kl=118.44	reconst_loss=6140.30	use 28.37 sec
|		batch #:1700	loss=6256.67	kl=118.87	reconst_loss=6137.80	use 28.32 sec
|		batch #:1800	loss=6247.32	kl=118.83	reconst_loss=6128.49	use 28.28 sec
|		batch #:1900	loss=6263.18	kl=118.62	reconst_loss=6144.55	use 28.28 sec
|		batch #:2000	loss=6257.44	kl=119.57	reconst_loss=6137.87	use 28.33 sec
|		batch #:2100	loss=6236.45	kl=118.35	reconst_loss=6118.09	use 28.35 sec
|		batch #:2200	loss=6263.55	kl=118.73	reconst_loss=6144.82	use 28.33 sec
|		batch #:2300	loss=6242.36	kl=119.61	reconst_loss=6122.75	use 28.30 sec
|		batch #:2400	loss=6259.12	kl=118.77	reconst_loss=6140.36	use 28.29 sec
|		batch #:2500	loss=6257.43	kl=118.66	reconst_loss=6138.78	use 28.32 sec
|		batch #:2600	loss=6252.33	kl=119.08	reconst_loss=6133.25	use 28.37 sec
|		batch #:2700	loss=6237.24	kl=118.83	reconst_loss=6118.41	use 28.36 sec
|		batch #:2800	loss=6263.50	kl=118.39	reconst_loss=6145.11	use 28.35 sec
|	Saving ./result/imgs/deconvolution_epoch_8_train.png...
|	Saving ./result/imgs/deconvolution_epoch_8_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_8_test.png...
|	Saving ./result/imgs/deconvolution_epoch_8_test_org.png...
|	Train loss=6256.806697182674

|		Eval test:
|		batch #:100	loss=6255.11	kl=119.34	reconst_loss=6135.77	use 10.89 sec
|		batch #:200	loss=6248.67	kl=119.74	reconst_loss=6128.92	use 10.57 sec
|		batch #:300	loss=6264.71	kl=119.22	reconst_loss=6145.49	use 10.58 sec
|	Test loss=6251.890904680083

Finished saving model: ./result/model/deconvolution8.pt
|	Epoch 9:
|		Train:
|		batch #:100	loss=6246.16	kl=118.76	reconst_loss=6127.40	use 28.09 sec
|		batch #:200	loss=6255.21	kl=118.15	reconst_loss=6137.07	use 28.33 sec
|		batch #:300	loss=6259.91	kl=119.17	reconst_loss=6140.74	use 28.36 sec
|		batch #:400	loss=6257.57	kl=118.97	reconst_loss=6138.59	use 28.38 sec
|		batch #:500	loss=6256.25	kl=118.83	reconst_loss=6137.42	use 28.37 sec
|		batch #:600	loss=6250.79	kl=118.51	reconst_loss=6132.28	use 28.35 sec
|		batch #:700	loss=6250.01	kl=118.38	reconst_loss=6131.63	use 28.34 sec
|		batch #:800	loss=6271.62	kl=119.01	reconst_loss=6152.61	use 28.35 sec
|		batch #:900	loss=6252.30	kl=119.10	reconst_loss=6133.21	use 28.31 sec
|		batch #:1000	loss=6258.20	kl=118.65	reconst_loss=6139.55	use 28.30 sec
|		batch #:1100	loss=6259.83	kl=119.28	reconst_loss=6140.55	use 28.31 sec
|		batch #:1200	loss=6244.85	kl=118.55	reconst_loss=6126.30	use 28.31 sec
|		batch #:1300	loss=6231.08	kl=118.85	reconst_loss=6112.23	use 28.32 sec
|		batch #:1400	loss=6247.12	kl=118.93	reconst_loss=6128.19	use 28.36 sec
|		batch #:1500	loss=6253.55	kl=118.62	reconst_loss=6134.92	use 28.34 sec
|		batch #:1600	loss=6254.62	kl=118.25	reconst_loss=6136.37	use 28.29 sec
|		batch #:1700	loss=6229.63	kl=119.24	reconst_loss=6110.39	use 28.29 sec
|		batch #:1800	loss=6246.07	kl=118.83	reconst_loss=6127.24	use 28.30 sec
|		batch #:1900	loss=6258.11	kl=118.99	reconst_loss=6139.12	use 28.30 sec
|		batch #:2000	loss=6232.03	kl=118.77	reconst_loss=6113.26	use 28.35 sec
|		batch #:2100	loss=6260.36	kl=118.65	reconst_loss=6141.71	use 28.35 sec
|		batch #:2200	loss=6250.62	kl=118.88	reconst_loss=6131.73	use 28.32 sec
|		batch #:2300	loss=6254.69	kl=118.66	reconst_loss=6136.03	use 28.31 sec
|		batch #:2400	loss=6277.05	kl=118.66	reconst_loss=6158.39	use 28.34 sec
|		batch #:2500	loss=6260.34	kl=118.45	reconst_loss=6141.88	use 28.37 sec
|		batch #:2600	loss=6269.25	kl=118.52	reconst_loss=6150.72	use 28.36 sec
|		batch #:2700	loss=6259.55	kl=118.35	reconst_loss=6141.20	use 28.33 sec
|		batch #:2800	loss=6234.32	kl=118.62	reconst_loss=6115.70	use 28.29 sec
|	Saving ./result/imgs/deconvolution_epoch_9_train.png...
|	Saving ./result/imgs/deconvolution_epoch_9_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_9_test.png...
|	Saving ./result/imgs/deconvolution_epoch_9_test_org.png...
|	Train loss=6253.271069618726

|		Eval test:
|		batch #:100	loss=6252.22	kl=116.29	reconst_loss=6135.93	use 10.89 sec
|		batch #:200	loss=6246.09	kl=116.61	reconst_loss=6129.48	use 10.57 sec
|		batch #:300	loss=6261.50	kl=116.17	reconst_loss=6145.33	use 10.58 sec
|	Test loss=6248.9637698402885

Finished saving model: ./result/model/deconvolution9.pt
|	Epoch 10:
|		Train:
|		batch #:100	loss=6255.14	kl=118.96	reconst_loss=6136.18	use 28.30 sec
|		batch #:200	loss=6251.79	kl=119.03	reconst_loss=6132.76	use 28.35 sec
|		batch #:300	loss=6236.33	kl=119.01	reconst_loss=6117.31	use 28.37 sec
|		batch #:400	loss=6265.36	kl=118.47	reconst_loss=6146.89	use 28.35 sec
|		batch #:500	loss=6259.06	kl=118.69	reconst_loss=6140.37	use 28.31 sec
|		batch #:600	loss=6257.25	kl=118.36	reconst_loss=6138.88	use 28.30 sec
|		batch #:700	loss=6253.47	kl=118.65	reconst_loss=6134.83	use 28.31 sec
|		batch #:800	loss=6252.46	kl=118.61	reconst_loss=6133.86	use 28.31 sec
|		batch #:900	loss=6268.83	kl=118.34	reconst_loss=6150.49	use 28.31 sec
|		batch #:1000	loss=6257.42	kl=118.43	reconst_loss=6138.98	use 28.30 sec
|		batch #:1100	loss=6237.42	kl=118.60	reconst_loss=6118.82	use 28.30 sec
|		batch #:1200	loss=6231.32	kl=118.60	reconst_loss=6112.72	use 28.31 sec
|		batch #:1300	loss=6250.37	kl=118.60	reconst_loss=6131.76	use 28.35 sec
|		batch #:1400	loss=6256.39	kl=118.49	reconst_loss=6137.90	use 28.34 sec
|		batch #:1500	loss=6234.91	kl=118.87	reconst_loss=6116.04	use 28.32 sec
|		batch #:1600	loss=6239.24	kl=118.72	reconst_loss=6120.52	use 28.27 sec
|		batch #:1700	loss=6262.00	kl=118.40	reconst_loss=6143.60	use 28.27 sec
|		batch #:1800	loss=6251.86	kl=118.69	reconst_loss=6133.16	use 28.29 sec
|		batch #:1900	loss=6253.04	kl=118.82	reconst_loss=6134.22	use 28.33 sec
|		batch #:2000	loss=6246.30	kl=118.29	reconst_loss=6128.01	use 28.33 sec
|		batch #:2100	loss=6249.22	kl=118.91	reconst_loss=6130.31	use 28.33 sec
|		batch #:2200	loss=6257.03	kl=118.40	reconst_loss=6138.63	use 28.32 sec
|		batch #:2300	loss=6225.24	kl=118.45	reconst_loss=6106.79	use 28.30 sec
|		batch #:2400	loss=6232.08	kl=118.95	reconst_loss=6113.13	use 28.30 sec
|		batch #:2500	loss=6249.27	kl=118.72	reconst_loss=6130.54	use 28.32 sec
|		batch #:2600	loss=6264.62	kl=118.14	reconst_loss=6146.48	use 28.31 sec
|		batch #:2700	loss=6253.83	kl=118.41	reconst_loss=6135.42	use 28.29 sec
|		batch #:2800	loss=6244.63	kl=118.06	reconst_loss=6126.58	use 28.28 sec
|	Saving ./result/imgs/deconvolution_epoch_10_train.png...
|	Saving ./result/imgs/deconvolution_epoch_10_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_10_test.png...
|	Saving ./result/imgs/deconvolution_epoch_10_test_org.png...
|	Train loss=6250.2393988639105

|		Eval test:
|		batch #:100	loss=6252.64	kl=117.68	reconst_loss=6134.96	use 10.95 sec
|		batch #:200	loss=6246.44	kl=118.08	reconst_loss=6128.36	use 10.56 sec
|		batch #:300	loss=6262.00	kl=117.68	reconst_loss=6144.32	use 10.57 sec
|	Test loss=6249.418004289458

Finished saving model: ./result/model/deconvolution10.pt
|	Epoch 11:
|		Train:
|		batch #:100	loss=6253.16	kl=118.72	reconst_loss=6134.44	use 28.06 sec
|		batch #:200	loss=6260.00	kl=118.49	reconst_loss=6141.51	use 28.33 sec
|		batch #:300	loss=6234.69	kl=118.61	reconst_loss=6116.08	use 28.36 sec
|		batch #:400	loss=6242.32	kl=118.64	reconst_loss=6123.68	use 28.33 sec
|		batch #:500	loss=6242.82	kl=118.95	reconst_loss=6123.87	use 28.31 sec
|		batch #:600	loss=6233.31	kl=118.38	reconst_loss=6114.93	use 28.33 sec
|		batch #:700	loss=6251.39	kl=118.77	reconst_loss=6132.63	use 28.39 sec
|		batch #:800	loss=6237.42	kl=118.64	reconst_loss=6118.78	use 28.40 sec
|		batch #:900	loss=6254.19	kl=118.68	reconst_loss=6135.51	use 28.38 sec
|		batch #:1000	loss=6266.46	kl=118.59	reconst_loss=6147.87	use 28.36 sec
|		batch #:1100	loss=6249.17	kl=118.23	reconst_loss=6130.94	use 28.32 sec
|		batch #:1200	loss=6250.60	kl=118.26	reconst_loss=6132.34	use 28.29 sec
|		batch #:1300	loss=6231.67	kl=118.36	reconst_loss=6113.31	use 28.32 sec
|		batch #:1400	loss=6261.37	kl=118.65	reconst_loss=6142.72	use 28.33 sec
|		batch #:1500	loss=6230.35	kl=118.63	reconst_loss=6111.72	use 28.33 sec
|		batch #:1600	loss=6251.85	kl=118.56	reconst_loss=6133.29	use 28.32 sec
|		batch #:1700	loss=6253.21	kl=118.01	reconst_loss=6135.20	use 28.30 sec
|		batch #:1800	loss=6257.62	kl=118.27	reconst_loss=6139.35	use 28.31 sec
|		batch #:1900	loss=6236.96	kl=118.34	reconst_loss=6118.62	use 28.32 sec
|		batch #:2000	loss=6241.08	kl=118.80	reconst_loss=6122.28	use 28.32 sec
|		batch #:2100	loss=6234.89	kl=118.47	reconst_loss=6116.41	use 28.30 sec
|		batch #:2200	loss=6244.90	kl=118.62	reconst_loss=6126.28	use 28.28 sec
|		batch #:2300	loss=6249.80	kl=118.59	reconst_loss=6131.22	use 28.28 sec
|		batch #:2400	loss=6258.43	kl=118.28	reconst_loss=6140.15	use 28.32 sec
|		batch #:2500	loss=6241.80	kl=119.14	reconst_loss=6122.66	use 28.35 sec
|		batch #:2600	loss=6247.08	kl=118.33	reconst_loss=6128.75	use 28.37 sec
|		batch #:2700	loss=6266.49	kl=118.08	reconst_loss=6148.41	use 28.37 sec
|		batch #:2800	loss=6244.20	kl=118.26	reconst_loss=6125.94	use 28.36 sec
|	Saving ./result/imgs/deconvolution_epoch_11_train.png...
|	Saving ./result/imgs/deconvolution_epoch_11_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_11_test.png...
|	Saving ./result/imgs/deconvolution_epoch_11_test_org.png...
|	Train loss=6247.572416102689

|		Eval test:
|		batch #:100	loss=6249.71	kl=117.58	reconst_loss=6132.13	use 10.90 sec
|		batch #:200	loss=6243.71	kl=117.88	reconst_loss=6125.83	use 10.57 sec
|		batch #:300	loss=6259.06	kl=117.54	reconst_loss=6141.52	use 10.56 sec
|	Test loss=6246.5889892578125

Finished saving model: ./result/model/deconvolution11.pt
|	Epoch 12:
|		Train:
|		batch #:100	loss=6244.29	kl=118.30	reconst_loss=6125.99	use 28.14 sec
|		batch #:200	loss=6230.40	kl=118.64	reconst_loss=6111.75	use 28.38 sec
|		batch #:300	loss=6253.16	kl=118.76	reconst_loss=6134.40	use 28.32 sec
|		batch #:400	loss=6251.39	kl=119.28	reconst_loss=6132.10	use 28.33 sec
|		batch #:500	loss=6226.62	kl=118.67	reconst_loss=6107.96	use 28.37 sec
|		batch #:600	loss=6257.89	kl=118.45	reconst_loss=6139.44	use 28.40 sec
|		batch #:700	loss=6242.55	kl=118.53	reconst_loss=6124.02	use 28.40 sec
|		batch #:800	loss=6248.82	kl=118.68	reconst_loss=6130.14	use 28.36 sec
|		batch #:900	loss=6247.58	kl=118.70	reconst_loss=6128.88	use 28.29 sec
|		batch #:1000	loss=6240.87	kl=118.58	reconst_loss=6122.28	use 28.31 sec
|		batch #:1100	loss=6247.23	kl=118.20	reconst_loss=6129.03	use 28.35 sec
|		batch #:1200	loss=6248.27	kl=118.10	reconst_loss=6130.17	use 28.37 sec
|		batch #:1300	loss=6233.01	kl=118.02	reconst_loss=6114.99	use 28.37 sec
|		batch #:1400	loss=6261.26	kl=118.29	reconst_loss=6142.97	use 28.35 sec
|		batch #:1500	loss=6235.78	kl=118.63	reconst_loss=6117.16	use 28.30 sec
|		batch #:1600	loss=6241.47	kl=118.61	reconst_loss=6122.86	use 28.29 sec
|		batch #:1700	loss=6239.31	kl=118.14	reconst_loss=6121.17	use 28.30 sec
|		batch #:1800	loss=6241.51	kl=118.41	reconst_loss=6123.10	use 28.31 sec
|		batch #:1900	loss=6266.54	kl=118.57	reconst_loss=6147.97	use 28.33 sec
|		batch #:2000	loss=6236.71	kl=117.94	reconst_loss=6118.77	use 28.34 sec
|		batch #:2100	loss=6232.53	kl=118.25	reconst_loss=6114.28	use 28.30 sec
|		batch #:2200	loss=6244.31	kl=118.25	reconst_loss=6126.06	use 28.31 sec
|		batch #:2300	loss=6245.77	kl=118.37	reconst_loss=6127.40	use 28.38 sec
|		batch #:2400	loss=6262.28	kl=118.34	reconst_loss=6143.93	use 28.42 sec
|		batch #:2500	loss=6241.46	kl=117.71	reconst_loss=6123.75	use 28.42 sec
|		batch #:2600	loss=6257.95	kl=118.77	reconst_loss=6139.19	use 28.35 sec
|		batch #:2700	loss=6259.15	kl=118.63	reconst_loss=6140.52	use 28.31 sec
|		batch #:2800	loss=6244.05	kl=117.85	reconst_loss=6126.19	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_12_train.png...
|	Saving ./result/imgs/deconvolution_epoch_12_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_12_test.png...
|	Saving ./result/imgs/deconvolution_epoch_12_test_org.png...
|	Train loss=6245.390193447811

|		Eval test:
|		batch #:100	loss=6248.52	kl=118.70	reconst_loss=6129.82	use 10.93 sec
|		batch #:200	loss=6242.38	kl=119.07	reconst_loss=6123.31	use 10.57 sec
|		batch #:300	loss=6257.99	kl=118.62	reconst_loss=6139.37	use 10.58 sec
|	Test loss=6245.355638721321

Finished saving model: ./result/model/deconvolution12.pt
|	Epoch 13:
|		Train:
|		batch #:100	loss=6212.09	kl=117.95	reconst_loss=6094.14	use 28.01 sec
|		batch #:200	loss=6237.61	kl=118.99	reconst_loss=6118.62	use 28.36 sec
|		batch #:300	loss=6223.18	kl=118.40	reconst_loss=6104.78	use 28.35 sec
|		batch #:400	loss=6248.43	kl=118.41	reconst_loss=6130.02	use 28.34 sec
|		batch #:500	loss=6244.39	kl=118.44	reconst_loss=6125.95	use 28.33 sec
|		batch #:600	loss=6240.52	kl=118.87	reconst_loss=6121.65	use 28.34 sec
|		batch #:700	loss=6254.81	kl=118.61	reconst_loss=6136.20	use 28.34 sec
|		batch #:800	loss=6243.14	kl=118.31	reconst_loss=6124.83	use 28.32 sec
|		batch #:900	loss=6265.84	kl=118.30	reconst_loss=6147.54	use 28.29 sec
|		batch #:1000	loss=6254.57	kl=117.63	reconst_loss=6136.94	use 28.33 sec
|		batch #:1100	loss=6256.13	kl=118.68	reconst_loss=6137.44	use 28.34 sec
|		batch #:1200	loss=6231.16	kl=117.93	reconst_loss=6113.23	use 28.36 sec
|		batch #:1300	loss=6247.00	kl=118.54	reconst_loss=6128.46	use 28.37 sec
|		batch #:1400	loss=6256.25	kl=118.10	reconst_loss=6138.15	use 28.33 sec
|		batch #:1500	loss=6226.25	kl=118.10	reconst_loss=6108.15	use 28.32 sec
|		batch #:1600	loss=6216.49	kl=118.02	reconst_loss=6098.47	use 28.34 sec
|		batch #:1700	loss=6266.45	kl=117.88	reconst_loss=6148.57	use 28.33 sec
|		batch #:1800	loss=6230.24	kl=118.75	reconst_loss=6111.49	use 28.33 sec
|		batch #:1900	loss=6280.92	kl=118.34	reconst_loss=6162.58	use 28.33 sec
|		batch #:2000	loss=6254.85	kl=118.02	reconst_loss=6136.83	use 28.33 sec
|		batch #:2100	loss=6258.23	kl=118.15	reconst_loss=6140.08	use 28.35 sec
|		batch #:2200	loss=6242.24	kl=117.85	reconst_loss=6124.39	use 28.35 sec
|		batch #:2300	loss=6252.15	kl=118.46	reconst_loss=6133.69	use 28.37 sec
|		batch #:2400	loss=6247.61	kl=118.29	reconst_loss=6129.32	use 28.32 sec
|		batch #:2500	loss=6248.36	kl=118.48	reconst_loss=6129.89	use 28.28 sec
|		batch #:2600	loss=6234.60	kl=118.80	reconst_loss=6115.80	use 28.30 sec
|		batch #:2700	loss=6220.66	kl=118.73	reconst_loss=6101.92	use 28.34 sec
|		batch #:2800	loss=6217.70	kl=118.18	reconst_loss=6099.52	use 28.36 sec
|	Saving ./result/imgs/deconvolution_epoch_13_train.png...
|	Saving ./result/imgs/deconvolution_epoch_13_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_13_test.png...
|	Saving ./result/imgs/deconvolution_epoch_13_test_org.png...
|	Train loss=6243.197856566997

|		Eval test:
|		batch #:100	loss=6245.56	kl=116.60	reconst_loss=6128.96	use 11.14 sec
|		batch #:200	loss=6239.49	kl=116.95	reconst_loss=6122.55	use 10.56 sec
|		batch #:300	loss=6255.41	kl=116.63	reconst_loss=6138.78	use 10.56 sec
|	Test loss=6242.5096188315865

Finished saving model: ./result/model/deconvolution13.pt
|	Epoch 14:
|		Train:
|		batch #:100	loss=6247.66	kl=118.64	reconst_loss=6129.02	use 28.31 sec
|		batch #:200	loss=6238.05	kl=118.84	reconst_loss=6119.21	use 28.32 sec
|		batch #:300	loss=6235.52	kl=118.75	reconst_loss=6116.77	use 28.37 sec
|		batch #:400	loss=6232.93	kl=118.94	reconst_loss=6113.99	use 28.34 sec
|		batch #:500	loss=6235.23	kl=118.72	reconst_loss=6116.51	use 28.35 sec
|		batch #:600	loss=6231.33	kl=118.39	reconst_loss=6112.94	use 28.34 sec
|		batch #:700	loss=6235.22	kl=117.96	reconst_loss=6117.26	use 28.32 sec
|		batch #:800	loss=6210.90	kl=118.29	reconst_loss=6092.61	use 28.35 sec
|		batch #:900	loss=6223.41	kl=118.57	reconst_loss=6104.84	use 28.39 sec
|		batch #:1000	loss=6257.48	kl=117.58	reconst_loss=6139.90	use 28.37 sec
|		batch #:1100	loss=6240.57	kl=118.47	reconst_loss=6122.10	use 28.35 sec
|		batch #:1200	loss=6220.90	kl=118.32	reconst_loss=6102.57	use 28.31 sec
|		batch #:1300	loss=6247.27	kl=118.62	reconst_loss=6128.65	use 28.22 sec
|		batch #:1400	loss=6259.15	kl=118.46	reconst_loss=6140.69	use 28.32 sec
|		batch #:1500	loss=6252.71	kl=118.44	reconst_loss=6134.27	use 28.33 sec
|		batch #:1600	loss=6247.23	kl=118.29	reconst_loss=6128.94	use 28.31 sec
|		batch #:1700	loss=6242.85	kl=117.87	reconst_loss=6124.97	use 28.33 sec
|		batch #:1800	loss=6245.03	kl=118.31	reconst_loss=6126.71	use 28.30 sec
|		batch #:1900	loss=6226.42	kl=118.42	reconst_loss=6108.01	use 28.31 sec
|		batch #:2000	loss=6253.21	kl=118.04	reconst_loss=6135.17	use 28.31 sec
|		batch #:2100	loss=6253.17	kl=118.16	reconst_loss=6135.00	use 28.29 sec
|		batch #:2200	loss=6263.05	kl=118.24	reconst_loss=6144.81	use 28.29 sec
|		batch #:2300	loss=6245.40	kl=117.93	reconst_loss=6127.46	use 28.31 sec
|		batch #:2400	loss=6215.94	kl=117.80	reconst_loss=6098.14	use 28.31 sec
|		batch #:2500	loss=6222.66	kl=118.54	reconst_loss=6104.13	use 28.33 sec
|		batch #:2600	loss=6264.30	kl=118.36	reconst_loss=6145.94	use 28.34 sec
|		batch #:2700	loss=6244.25	kl=117.95	reconst_loss=6126.30	use 28.39 sec
|		batch #:2800	loss=6252.07	kl=118.40	reconst_loss=6133.68	use 28.34 sec
|	Saving ./result/imgs/deconvolution_epoch_14_train.png...
|	Saving ./result/imgs/deconvolution_epoch_14_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_14_test.png...
|	Saving ./result/imgs/deconvolution_epoch_14_test_org.png...
|	Train loss=6241.473013248892

|		Eval test:
|		batch #:100	loss=6246.10	kl=117.79	reconst_loss=6128.31	use 10.91 sec
|		batch #:200	loss=6239.58	kl=118.17	reconst_loss=6121.41	use 10.58 sec
|		batch #:300	loss=6255.39	kl=117.78	reconst_loss=6137.61	use 10.59 sec
|	Test loss=6242.72158697587

Finished saving model: ./result/model/deconvolution14.pt
|	Epoch 15:
|		Train:
|		batch #:100	loss=6242.42	kl=118.49	reconst_loss=6123.94	use 28.41 sec
|		batch #:200	loss=6216.84	kl=117.99	reconst_loss=6098.85	use 28.40 sec
|		batch #:300	loss=6231.19	kl=118.10	reconst_loss=6113.09	use 28.41 sec
|		batch #:400	loss=6241.07	kl=117.73	reconst_loss=6123.33	use 28.41 sec
|		batch #:500	loss=6256.64	kl=118.07	reconst_loss=6138.57	use 28.35 sec
|		batch #:600	loss=6255.58	kl=118.66	reconst_loss=6136.92	use 28.32 sec
|		batch #:700	loss=6241.96	kl=118.64	reconst_loss=6123.32	use 28.34 sec
|		batch #:800	loss=6235.53	kl=118.15	reconst_loss=6117.38	use 28.33 sec
|		batch #:900	loss=6249.20	kl=118.57	reconst_loss=6130.64	use 28.32 sec
|		batch #:1000	loss=6230.57	kl=118.14	reconst_loss=6112.43	use 28.32 sec
|		batch #:1100	loss=6217.81	kl=118.42	reconst_loss=6099.38	use 28.31 sec
|		batch #:1200	loss=6235.27	kl=118.40	reconst_loss=6116.87	use 28.32 sec
|		batch #:1300	loss=6251.07	kl=118.11	reconst_loss=6132.95	use 28.35 sec
|		batch #:1400	loss=6230.03	kl=119.08	reconst_loss=6110.94	use 28.36 sec
|		batch #:1500	loss=6253.64	kl=117.86	reconst_loss=6135.79	use 28.34 sec
|		batch #:1600	loss=6239.04	kl=118.77	reconst_loss=6120.27	use 28.32 sec
|		batch #:1700	loss=6244.54	kl=117.80	reconst_loss=6126.74	use 28.29 sec
|		batch #:1800	loss=6229.58	kl=118.05	reconst_loss=6111.53	use 28.28 sec
|		batch #:1900	loss=6255.50	kl=118.34	reconst_loss=6137.17	use 28.31 sec
|		batch #:2000	loss=6244.44	kl=118.32	reconst_loss=6126.12	use 28.32 sec
|		batch #:2100	loss=6247.17	kl=118.71	reconst_loss=6128.46	use 28.31 sec
|		batch #:2200	loss=6230.37	kl=118.40	reconst_loss=6111.97	use 28.32 sec
|		batch #:2300	loss=6251.72	kl=118.41	reconst_loss=6133.32	use 28.32 sec
|		batch #:2400	loss=6239.88	kl=118.45	reconst_loss=6121.43	use 28.33 sec
|		batch #:2500	loss=6227.82	kl=117.81	reconst_loss=6110.01	use 28.34 sec
|		batch #:2600	loss=6223.93	kl=118.70	reconst_loss=6105.23	use 28.31 sec
|		batch #:2700	loss=6242.18	kl=117.78	reconst_loss=6124.41	use 28.29 sec
|		batch #:2800	loss=6245.40	kl=118.34	reconst_loss=6127.06	use 28.31 sec
|	Saving ./result/imgs/deconvolution_epoch_15_train.png...
|	Saving ./result/imgs/deconvolution_epoch_15_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_15_test.png...
|	Saving ./result/imgs/deconvolution_epoch_15_test_org.png...
|	Train loss=6239.700194112792

|		Eval test:
|		batch #:100	loss=6241.58	kl=118.16	reconst_loss=6123.42	use 10.91 sec
|		batch #:200	loss=6235.45	kl=118.54	reconst_loss=6116.91	use 10.57 sec
|		batch #:300	loss=6250.83	kl=118.11	reconst_loss=6132.72	use 10.57 sec
|	Test loss=6238.304588607595

Finished saving model: ./result/model/deconvolution15.pt
|	Epoch 16:
|		Train:
|		batch #:100	loss=6240.43	kl=118.45	reconst_loss=6121.97	use 28.39 sec
|		batch #:200	loss=6224.38	kl=118.68	reconst_loss=6105.70	use 28.34 sec
|		batch #:300	loss=6264.75	kl=118.51	reconst_loss=6146.24	use 28.32 sec
|		batch #:400	loss=6229.90	kl=118.18	reconst_loss=6111.72	use 28.32 sec
|		batch #:500	loss=6238.96	kl=118.45	reconst_loss=6120.50	use 28.31 sec
|		batch #:600	loss=6250.18	kl=118.32	reconst_loss=6131.87	use 28.29 sec
|		batch #:700	loss=6271.33	kl=118.72	reconst_loss=6152.61	use 28.31 sec
|		batch #:800	loss=6224.63	kl=118.12	reconst_loss=6106.51	use 28.35 sec
|		batch #:900	loss=6228.59	kl=118.60	reconst_loss=6109.99	use 28.36 sec
|		batch #:1000	loss=6239.67	kl=118.36	reconst_loss=6121.31	use 28.34 sec
|		batch #:1100	loss=6232.20	kl=118.15	reconst_loss=6114.05	use 28.34 sec
|		batch #:1200	loss=6222.52	kl=118.34	reconst_loss=6104.18	use 28.32 sec
|		batch #:1300	loss=6229.30	kl=117.81	reconst_loss=6111.49	use 28.34 sec
|		batch #:1400	loss=6240.89	kl=118.13	reconst_loss=6122.77	use 28.34 sec
|		batch #:1500	loss=6224.52	kl=118.22	reconst_loss=6106.31	use 28.33 sec
|		batch #:1600	loss=6263.66	kl=118.25	reconst_loss=6145.41	use 28.29 sec
|		batch #:1700	loss=6243.08	kl=118.04	reconst_loss=6125.04	use 28.30 sec
|		batch #:1800	loss=6235.05	kl=118.00	reconst_loss=6117.05	use 28.31 sec
|		batch #:1900	loss=6239.50	kl=118.12	reconst_loss=6121.39	use 28.33 sec
|		batch #:2000	loss=6240.06	kl=119.07	reconst_loss=6120.99	use 28.34 sec
|		batch #:2100	loss=6239.77	kl=118.32	reconst_loss=6121.45	use 28.33 sec
|		batch #:2200	loss=6226.51	kl=118.19	reconst_loss=6108.32	use 28.31 sec
|		batch #:2300	loss=6223.43	kl=118.64	reconst_loss=6104.79	use 28.30 sec
|		batch #:2400	loss=6231.73	kl=118.30	reconst_loss=6113.43	use 28.29 sec
|		batch #:2500	loss=6230.47	kl=118.12	reconst_loss=6112.35	use 28.29 sec
|		batch #:2600	loss=6236.85	kl=118.32	reconst_loss=6118.53	use 28.32 sec
|		batch #:2700	loss=6248.96	kl=117.78	reconst_loss=6131.19	use 28.33 sec
|		batch #:2800	loss=6241.23	kl=118.15	reconst_loss=6123.08	use 28.34 sec
|	Saving ./result/imgs/deconvolution_epoch_16_train.png...
|	Saving ./result/imgs/deconvolution_epoch_16_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_16_test.png...
|	Saving ./result/imgs/deconvolution_epoch_16_test_org.png...
|	Train loss=6238.123814859655

|		Eval test:
|		batch #:100	loss=6243.00	kl=117.36	reconst_loss=6125.63	use 10.95 sec
|		batch #:200	loss=6236.98	kl=117.68	reconst_loss=6119.30	use 10.58 sec
|		batch #:300	loss=6252.65	kl=117.32	reconst_loss=6135.34	use 10.58 sec
|	Test loss=6239.942503337618

Finished saving model: ./result/model/deconvolution16.pt
|	Epoch 17:
|		Train:
|		batch #:100	loss=6237.16	kl=118.54	reconst_loss=6118.63	use 28.35 sec
|		batch #:200	loss=6224.90	kl=118.37	reconst_loss=6106.53	use 28.36 sec
|		batch #:300	loss=6218.57	kl=118.81	reconst_loss=6099.75	use 28.35 sec
|		batch #:400	loss=6230.93	kl=118.87	reconst_loss=6112.06	use 28.34 sec
|		batch #:500	loss=6226.04	kl=118.59	reconst_loss=6107.45	use 28.36 sec
|		batch #:600	loss=6241.80	kl=117.94	reconst_loss=6123.86	use 28.37 sec
|		batch #:700	loss=6238.81	kl=118.22	reconst_loss=6120.59	use 28.40 sec
|		batch #:800	loss=6242.51	kl=118.07	reconst_loss=6124.44	use 28.38 sec
|		batch #:900	loss=6240.67	kl=118.21	reconst_loss=6122.46	use 28.34 sec
|		batch #:1000	loss=6248.28	kl=118.25	reconst_loss=6130.03	use 28.33 sec
|		batch #:1100	loss=6234.34	kl=117.99	reconst_loss=6116.35	use 28.32 sec
|		batch #:1200	loss=6238.90	kl=118.46	reconst_loss=6120.44	use 28.33 sec
|		batch #:1300	loss=6234.15	kl=118.23	reconst_loss=6115.92	use 28.35 sec
|		batch #:1400	loss=6230.18	kl=117.88	reconst_loss=6112.30	use 28.34 sec
|		batch #:1500	loss=6223.60	kl=118.43	reconst_loss=6105.17	use 28.32 sec
|		batch #:1600	loss=6237.36	kl=118.41	reconst_loss=6118.95	use 28.34 sec
|		batch #:1700	loss=6230.78	kl=117.91	reconst_loss=6112.88	use 28.33 sec
|		batch #:1800	loss=6246.43	kl=118.07	reconst_loss=6128.36	use 28.33 sec
|		batch #:1900	loss=6235.08	kl=118.51	reconst_loss=6116.57	use 28.34 sec
|		batch #:2000	loss=6253.95	kl=118.59	reconst_loss=6135.37	use 28.34 sec
|		batch #:2100	loss=6246.47	kl=118.53	reconst_loss=6127.94	use 28.29 sec
|		batch #:2200	loss=6247.69	kl=118.39	reconst_loss=6129.30	use 28.28 sec
|		batch #:2300	loss=6243.05	kl=118.06	reconst_loss=6125.00	use 28.29 sec
|		batch #:2400	loss=6228.34	kl=117.94	reconst_loss=6110.40	use 28.35 sec
|		batch #:2500	loss=6260.72	kl=117.95	reconst_loss=6142.76	use 28.40 sec
|		batch #:2600	loss=6253.07	kl=118.04	reconst_loss=6135.02	use 28.37 sec
|		batch #:2700	loss=6221.53	kl=118.42	reconst_loss=6103.11	use 28.33 sec
|		batch #:2800	loss=6213.63	kl=118.53	reconst_loss=6095.10	use 28.31 sec
|	Saving ./result/imgs/deconvolution_epoch_17_train.png...
|	Saving ./result/imgs/deconvolution_epoch_17_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_17_test.png...
|	Saving ./result/imgs/deconvolution_epoch_17_test_org.png...
|	Train loss=6236.825015184879

|		Eval test:
|		batch #:100	loss=6240.99	kl=117.91	reconst_loss=6123.08	use 10.90 sec
|		batch #:200	loss=6235.08	kl=118.32	reconst_loss=6116.77	use 10.58 sec
|		batch #:300	loss=6250.41	kl=117.88	reconst_loss=6132.53	use 10.59 sec
|	Test loss=6237.880165582971

Finished saving model: ./result/model/deconvolution17.pt
|	Epoch 18:
|		Train:
|		batch #:100	loss=6241.45	kl=118.37	reconst_loss=6123.08	use 28.46 sec
|		batch #:200	loss=6225.60	kl=118.66	reconst_loss=6106.94	use 28.34 sec
|		batch #:300	loss=6240.60	kl=118.45	reconst_loss=6122.15	use 28.34 sec
|		batch #:400	loss=6246.34	kl=118.42	reconst_loss=6127.91	use 28.32 sec
|		batch #:500	loss=6238.41	kl=117.90	reconst_loss=6120.51	use 28.28 sec
|		batch #:600	loss=6256.85	kl=118.10	reconst_loss=6138.75	use 28.30 sec
|		batch #:700	loss=6257.27	kl=117.93	reconst_loss=6139.35	use 28.34 sec
|		batch #:800	loss=6265.11	kl=117.97	reconst_loss=6147.14	use 28.33 sec
|		batch #:900	loss=6226.84	kl=117.96	reconst_loss=6108.87	use 28.31 sec
|		batch #:1000	loss=6219.73	kl=118.70	reconst_loss=6101.03	use 28.32 sec
|		batch #:1100	loss=6236.78	kl=118.26	reconst_loss=6118.52	use 28.29 sec
|		batch #:1200	loss=6235.21	kl=117.92	reconst_loss=6117.28	use 28.30 sec
|		batch #:1300	loss=6231.62	kl=118.42	reconst_loss=6113.21	use 28.34 sec
|		batch #:1400	loss=6242.01	kl=118.07	reconst_loss=6123.94	use 28.34 sec
|		batch #:1500	loss=6226.31	kl=118.79	reconst_loss=6107.51	use 28.34 sec
|		batch #:1600	loss=6217.45	kl=118.42	reconst_loss=6099.03	use 28.31 sec
|		batch #:1700	loss=6243.89	kl=118.76	reconst_loss=6125.13	use 28.30 sec
|		batch #:1800	loss=6232.77	kl=117.91	reconst_loss=6114.86	use 28.29 sec
|		batch #:1900	loss=6238.91	kl=117.80	reconst_loss=6121.11	use 28.28 sec
|		batch #:2000	loss=6231.11	kl=118.21	reconst_loss=6112.91	use 28.30 sec
|		batch #:2100	loss=6245.35	kl=118.21	reconst_loss=6127.14	use 28.30 sec
|		batch #:2200	loss=6224.26	kl=118.84	reconst_loss=6105.41	use 28.31 sec
|		batch #:2300	loss=6228.73	kl=118.36	reconst_loss=6110.37	use 28.31 sec
|		batch #:2400	loss=6241.11	kl=118.66	reconst_loss=6122.45	use 28.32 sec
|		batch #:2500	loss=6234.55	kl=118.13	reconst_loss=6116.42	use 28.26 sec
|		batch #:2600	loss=6224.29	kl=118.37	reconst_loss=6105.92	use 28.31 sec
|		batch #:2700	loss=6209.10	kl=118.69	reconst_loss=6090.41	use 28.32 sec
|		batch #:2800	loss=6237.55	kl=118.42	reconst_loss=6119.13	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_18_train.png...
|	Saving ./result/imgs/deconvolution_epoch_18_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_18_test.png...
|	Saving ./result/imgs/deconvolution_epoch_18_test_org.png...
|	Train loss=6235.551889609019

|		Eval test:
|		batch #:100	loss=6241.67	kl=118.12	reconst_loss=6123.55	use 10.90 sec
|		batch #:200	loss=6235.85	kl=118.39	reconst_loss=6117.47	use 10.58 sec
|		batch #:300	loss=6251.36	kl=118.14	reconst_loss=6133.22	use 10.57 sec
|	Test loss=6238.668070732792

Finished saving model: ./result/model/deconvolution18.pt
|	Epoch 19:
|		Train:
|		batch #:100	loss=6229.79	kl=119.15	reconst_loss=6110.65	use 28.35 sec
|		batch #:200	loss=6228.38	kl=118.52	reconst_loss=6109.87	use 28.33 sec
|		batch #:300	loss=6235.38	kl=117.96	reconst_loss=6117.42	use 28.35 sec
|		batch #:400	loss=6223.89	kl=118.56	reconst_loss=6105.33	use 28.36 sec
|		batch #:500	loss=6232.01	kl=118.44	reconst_loss=6113.57	use 28.35 sec
|		batch #:600	loss=6231.54	kl=118.95	reconst_loss=6112.59	use 28.39 sec
|		batch #:700	loss=6252.25	kl=118.44	reconst_loss=6133.81	use 28.36 sec
|		batch #:800	loss=6226.78	kl=118.55	reconst_loss=6108.23	use 28.35 sec
|		batch #:900	loss=6228.61	kl=118.62	reconst_loss=6109.99	use 28.34 sec
|		batch #:1000	loss=6233.20	kl=118.46	reconst_loss=6114.74	use 28.31 sec
|		batch #:1100	loss=6220.84	kl=118.55	reconst_loss=6102.29	use 28.33 sec
|		batch #:1200	loss=6221.72	kl=118.47	reconst_loss=6103.25	use 28.35 sec
|		batch #:1300	loss=6225.81	kl=118.47	reconst_loss=6107.35	use 28.34 sec
|		batch #:1400	loss=6242.88	kl=118.26	reconst_loss=6124.63	use 28.32 sec
|		batch #:1500	loss=6232.83	kl=117.96	reconst_loss=6114.87	use 28.31 sec
|		batch #:1600	loss=6257.15	kl=117.65	reconst_loss=6139.50	use 28.28 sec
|		batch #:1700	loss=6223.05	kl=118.58	reconst_loss=6104.47	use 28.29 sec
|		batch #:1800	loss=6229.66	kl=118.12	reconst_loss=6111.54	use 28.29 sec
|		batch #:1900	loss=6241.16	kl=117.74	reconst_loss=6123.42	use 28.31 sec
|		batch #:2000	loss=6257.53	kl=118.22	reconst_loss=6139.31	use 28.33 sec
|		batch #:2100	loss=6235.42	kl=118.49	reconst_loss=6116.93	use 28.33 sec
|		batch #:2200	loss=6233.64	kl=118.28	reconst_loss=6115.36	use 28.31 sec
|		batch #:2300	loss=6224.87	kl=118.35	reconst_loss=6106.52	use 28.35 sec
|		batch #:2400	loss=6236.42	kl=118.39	reconst_loss=6118.04	use 28.36 sec
|		batch #:2500	loss=6230.35	kl=117.65	reconst_loss=6112.70	use 28.36 sec
|		batch #:2600	loss=6236.19	kl=118.25	reconst_loss=6117.93	use 28.35 sec
|		batch #:2700	loss=6238.25	kl=118.05	reconst_loss=6120.19	use 28.34 sec
|		batch #:2800	loss=6244.41	kl=117.85	reconst_loss=6126.57	use 28.33 sec
|	Saving ./result/imgs/deconvolution_epoch_19_train.png...
|	Saving ./result/imgs/deconvolution_epoch_19_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_19_test.png...
|	Saving ./result/imgs/deconvolution_epoch_19_test_org.png...
|	Train loss=6234.1874340160475

|		Eval test:
|		batch #:100	loss=6240.41	kl=115.92	reconst_loss=6124.49	use 10.93 sec
|		batch #:200	loss=6234.53	kl=116.25	reconst_loss=6118.28	use 10.59 sec
|		batch #:300	loss=6250.32	kl=115.88	reconst_loss=6134.44	use 10.58 sec
|	Test loss=6237.4207825479625

Finished saving model: ./result/model/deconvolution19.pt
|	Epoch 20:
|		Train:
|		batch #:100	loss=6213.94	kl=118.80	reconst_loss=6095.14	use 28.45 sec
|		batch #:200	loss=6255.43	kl=118.35	reconst_loss=6137.08	use 28.36 sec
|		batch #:300	loss=6202.28	kl=118.15	reconst_loss=6084.12	use 28.36 sec
|		batch #:400	loss=6226.62	kl=118.21	reconst_loss=6108.41	use 28.33 sec
|		batch #:500	loss=6202.52	kl=118.65	reconst_loss=6083.87	use 28.32 sec
|		batch #:600	loss=6234.95	kl=118.87	reconst_loss=6116.08	use 28.31 sec
|		batch #:700	loss=6240.93	kl=118.68	reconst_loss=6122.25	use 28.29 sec
|		batch #:800	loss=6243.32	kl=118.47	reconst_loss=6124.85	use 28.31 sec
|		batch #:900	loss=6256.09	kl=118.24	reconst_loss=6137.85	use 28.34 sec
|		batch #:1000	loss=6238.31	kl=118.29	reconst_loss=6120.02	use 28.34 sec
|		batch #:1100	loss=6217.89	kl=118.41	reconst_loss=6099.47	use 28.38 sec
|		batch #:1200	loss=6221.90	kl=118.55	reconst_loss=6103.35	use 28.36 sec
|		batch #:1300	loss=6228.97	kl=117.95	reconst_loss=6111.03	use 28.34 sec
|		batch #:1400	loss=6261.13	kl=118.62	reconst_loss=6142.51	use 28.32 sec
|		batch #:1500	loss=6230.94	kl=118.43	reconst_loss=6112.52	use 28.29 sec
|		batch #:1600	loss=6222.31	kl=118.61	reconst_loss=6103.70	use 28.30 sec
|		batch #:1700	loss=6238.97	kl=119.06	reconst_loss=6119.91	use 28.28 sec
|		batch #:1800	loss=6214.24	kl=118.24	reconst_loss=6096.00	use 28.31 sec
|		batch #:1900	loss=6248.44	kl=118.28	reconst_loss=6130.16	use 28.31 sec
|		batch #:2000	loss=6258.30	kl=118.10	reconst_loss=6140.20	use 28.30 sec
|		batch #:2100	loss=6245.04	kl=118.61	reconst_loss=6126.43	use 28.31 sec
|		batch #:2200	loss=6251.26	kl=117.76	reconst_loss=6133.49	use 28.33 sec
|		batch #:2300	loss=6243.90	kl=117.98	reconst_loss=6125.91	use 28.34 sec
|		batch #:2400	loss=6223.33	kl=118.13	reconst_loss=6105.20	use 28.34 sec
|		batch #:2500	loss=6207.16	kl=118.37	reconst_loss=6088.80	use 28.31 sec
|		batch #:2600	loss=6221.90	kl=117.70	reconst_loss=6104.20	use 28.29 sec
|		batch #:2700	loss=6248.97	kl=118.34	reconst_loss=6130.63	use 28.27 sec
|		batch #:2800	loss=6228.35	kl=118.63	reconst_loss=6109.72	use 28.30 sec
|	Saving ./result/imgs/deconvolution_epoch_20_train.png...
|	Saving ./result/imgs/deconvolution_epoch_20_train_org.png...
|	Saving ./result/imgs/deconvolution_epoch_20_test.png...
|	Saving ./result/imgs/deconvolution_epoch_20_test_org.png...
|	Train loss=6232.96034998574

|		Eval test:
|		batch #:100	loss=6239.12	kl=114.30	reconst_loss=6124.82	use 10.90 sec
|		batch #:200	loss=6233.36	kl=114.66	reconst_loss=6118.70	use 10.58 sec
|		batch #:300	loss=6248.95	kl=114.38	reconst_loss=6134.56	use 10.58 sec
|	Test loss=6236.223396397844

Finished saving model: ./result/model/deconvolution20.pt
|	Saving ./result/imgs/deconvolution_reconstruction_z_train.png...
|	Saving ./result/imgs/deconvolution_reconstruction_im_train.png...
|	Saving ./result/imgs/deconvolution_reconstruction_z_test.png...
|	Saving ./result/imgs/deconvolution_reconstruction_im_test.png...
slurmstepd-leto07: error: Exceeded step memory limit at some point.
